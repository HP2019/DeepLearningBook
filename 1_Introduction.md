# 第一章 引言

**挑战：**

人工智能的真正挑战在于解决那些对人来说很容易执行、但很难**形式化描述**的任务，如识别人们所说的话或图像中的脸。对于这些问题，我们人类往往可以凭借直觉轻易地解决。针对这些比较直观的问题，本书讨论一种解决方案。

- 该方案可以让计算机**从经验中学习**，并根据**层次化的概念体系**来理解世界，而每个概念则通过与某些相对简单的概念之间的关系来定义。
  - 让计算机从经验获取知识，可以避免由人类来给计算机形式化地指定它需要的所有知识。
  - 层次化的概念让计算机构建较简单的概念来学习复杂概念。
- 如果绘制出这些概念如何建立在彼此之上的图，我们将得到一张 ‘‘深’’（层次很多）的图。基于这个原因，我们称这种方法为 AI **深度学习**（ deep learning）。

**方案：**

一个人的日常生活需要关于世界的巨量知识。计算机需要获取同样的知识才能表现出智能。 人工智能的一个关键挑战就是如何将这些非形式化的知识传达给计算机。

- 一些人工智能项目力求将关于世界的知识用形式化的语言进行**硬编码** (hardcode)。计算机可以使用逻辑推理规则来自动地理解这些形式化语言中的声明。这就是众所周知的人工智能的 **知识库**（ knowledge base）方法。然而，这些项目最终都没有取得重大的成功。
- 依靠硬编码的知识体系面对的困难表明， AI 系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。这种能力被称为 **机器学习**（ machine learning）。

**深度学习与表示学习：**

简单的机器学习算法的性能在很大程度上依赖于给定数据的 **表示**（ representation）。

<img src=assets/1_1.png height=300 >

*图 1.1: 不同表示的例子：假设我们想在散点图中画一条线来分隔两类数据。在左图，我们使用笛*
*卡尔坐标表示数据，这个任务是不可能的。右图中，我们用极坐标表示数据，可以用垂直线简单地*
*解决这个任务。*

许多人工智能任务都可以通过以下方式解决：先提取一个合适的特征集，然后将这些特征提供给简单的机器学习算法。然而，对于许多任务来说，我们很难知道应该提取哪些特征。

解决这个问题的途径之一是**使用机器学习来发掘表示本身**，而不仅仅把表示映射到输出。这种方法我们称之为 **表示学习**（ representation learning）。学习到的表示往往比手动设计的表示表现得更好。



表示学习算法的典型例子是 **自编码器**（ autoencoder）。 

- 自编码器由一个 编码器（ encoder）函数和一个 解码器（ decoder）函数组合而成。 编码器函数将输入数据转换为一种不同的表示，而解码器函数则将这个新的表示转换到原来的形式。
- 我们期望当输入数据经过编码器和解码器之后尽可能多地保留信息，同时希望新的表示有各种好的特性，这也是自编码器的训练目标。
- 为了实现不同的特性，我们可以设计不同形式的自编码器。



当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观察数据的 **变差因素**（ factors of variation）。

- 在此背景下， ‘‘因素’’ 这个词仅指代影响的不同来源；因素通常不是乘性组合。这些因素通常是不能被直接观察到的量。相反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的量。
- 为了对观察到的数据提供有用的简化解释或推断其原因，它们还可能以概念的形式存在于人类的思维中。它们可以被看作数据的概念或者抽象，帮助我们了解这些数据的丰富多样性。
- 当分析语音记录时， 变差因素包括说话者的年龄、性别、（无法直接观测）他们(概念)的口音和他们正在说的词语。当分析汽车的图像时， 变差因素包括汽车的位置、它的颜色、太阳的角度和亮度。
- 在许多现实的人工智能应用中，困难主要源于多个变差因素同时影响着我们能够观察到的每一个数据。

显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难，因此，乍一看， 表示学习似乎并不能帮助我们。

***深度学习（ deep learning）通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。***

<img src=assets/1_2.png height=300>

*图 1.2: 深度学习模型的示意图。给定像素，第一层可以轻易地通过比较相邻像素的亮度来识别边缘。有了第一隐藏层描述的边缘，第二隐藏层可以容易地搜索可识别为角和扩展轮廓的边集合。给定第二隐藏层中关于角和轮廓的图像描述，第三隐藏层可以找到轮廓和角的特定集合来检测特定对象的整个部分。最后，根据图像描述中包含的对象部分，可以识别图像中存在的对象。*



深度学习模型的典型例子是前馈深度网络或 多层感知机（ multilayer perceptron, MLP）。

- 多层感知机仅仅是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。

*学习数据的正确表示的想法是解释深度学习的一个视角。另一个视角是深度促使计算机学习一个多步骤的计算机程序。*

<img src=assets/1_4.png height=300 >

*图 1.4: 维恩图展示了深度学习是一种表示学习，也是一种机器学习，可以用于许多（但不是全部）*
*AI 方法。维恩图的每个部分包括一个 AI 技术的示例。*

<img src=assets/1_5.png height=500 >

图 1.5: 流程图展示了 AI 系统的不同部分如何在不同的 AI 学科中彼此相关。阴影框表示能从数
据中学习的组件。

## 1.2 深度学习的历史趋势

### 1.2.1 神经网络的众多名称和命运变迁

目前为止深度学习已经经历了三次发展浪潮： 20 世纪40 年代到 60 年代深度学习的雏形出现在 **控制论**（ cybernetics）中， 20 世纪 80 年代到 90 年代深度学习表现为 **联结主义**（ connectionism），直到 2006 年，才真正以**深度学习**之名复兴。

**控制论：**

现代深度学习的最早前身是从神经科学的角度出发的简单线性模型。这些模型被设计为使用一组 $n$ 个输入 $x_1, ... , x_n$ 并将它们与一个输出 $y$ 相关联。这些模型希望学习一组权重 $w_1,..., w_n$，并计算它们的输出 $f(x,w) = x_1w_1 + ... + x_nw_n$。这第一波神经网络研究浪潮被称为控制论。

- McCulloch-Pitts 神经元 (McCulloch and Pitts, 1943) 是脑功能的早期模型。该线性模型通过检验函数 f(x; w) 的正负来识别两种不同类别的输入。显然，模型的权重需要正确设置后才能使模型的输出对应于期望的类别。这些权重可以由操作人员设定。
- 在 20 世纪 50 年代，感知机 (Rosenblatt, 1956, 1958) 成为第一个能根据每个类别的输入样本来学习权重的模型。约在同一时期， 自适应线性单元 (adaptive linear element, ADALINE) 简单地返回函数 f(x) 本身的值来预测一个实数 (Widrow and Hoff, 1960)，并且它还可以学习从数据预测这些数。

基于感知机和 ADALINE 中使用的函数 f(x; w) 的模型被称为 线性模型（ linear model）。

- 线性模型有很多局限性。最著名的是，它们无法学习异或（ XOR）函数，即$f([0; 1]; w) = 1$ 和 $f([1; 0]; w) = 1$，但 $f([1; 1]; w) = 0$ 和 $f([0; 0]; w) = 0$。

***现在，神经科学被视为深度学习研究的一个重要灵感来源，但它已不再是该领域的主要指导。目前大多数神经网络是基于一个称为 整流线性单元（ rectified linear unit）的神经单元模型。真实的神经元计算着与现代整流线性单元非常不同的函数，但更接近真实神经网络的系统并没有导致机器学习性能的提升。***



**联结主义**

在 20 世纪 80 年代，神经网络研究的第二次浪潮在很大程度上是伴随一个被称为 **联结主义**（ connectionism）或**并行分布处理** ( parallel distributed processing) 潮流而出现的。

- 联结主义的中心思想是，当网络将大量简单的计算单元连接在一起时可以实现
  智能行为。
- 其中一个概念是 分布式表示（ distributed representation） (Hinton et al., 1986)。
  其思想是：系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与
  到多个可能输入的表示。例如，假设我们有一个能够识别红色、绿色、或蓝色的汽
  车、卡车和鸟类的视觉系统， 表示这些输入的其中一个方法是将九个可能的组合：红
  卡车，红汽车，红鸟，绿卡车等等使用单独的神经元或隐藏单元激活。这需要九个
  不同的神经元，并且每个神经必须独立地学习颜色和对象身份的概念。改善这种情
  况的方法之一是使用分布式表示，即用三个神经元描述颜色，三个神经元描述对象
  身份。这仅仅需要 6 个神经元而不是 9 个，并且描述红色的神经元能够从汽车、卡
  车和鸟类的图像中学习红色，而不仅仅是从一个特定类别的图像中学习。 
- 联结主义潮流的另一个重要成就是反向传播在训练具有内部表示的深度神经网络中的成功使用以及**反向传播算法**的普及

- 在 20 世纪 90 年代，研究人员在使用神经网络进行序列建模的方面取得了重要进展。 Hochreiter (1991b) 和 Bengio et al. (1994a) 指出了对长序列进行建模的一些根本性数学难题，Hochreiter and Schmidhuber (1997)引入 长短期记忆（ long short-term memory, LSTM）网络来解决这些难题。

**深度学习：**

神经网络研究的第三次浪潮始于 2006 年的突破。 Geoffrey Hinton 表明名为**深度信念网络**的神经网络可以使用一种称为贪婪逐层预训练的策略来有效地训练。

第三次浪潮已开始着眼于新的**无监督学习技术**和**深度模型在小数据集的泛化能力**，但目前更
多的兴趣点仍是比较传统的监督学习算法和深度模型充分利用大型标注数据集的能力。

### 

### 1.2.2 与日俱增的数据量

截至 2016 年，一个粗略的经验法则是，监督深度学习算法在每类给定约 5000 个标注样本情况下一般将达到可以接受的性能，当至少有 1000 万个标注样本的数据集用于训练时，它将达到或超过人类表现。

此外，在更小的数据集上获得成功是一个重要的研究领域，为此我们应特别侧重于如何通过无监督或半监督学习充分利用大量的未标注样本。

### 1.2.3 与日俱增的模型规模

20 世纪 80 年代， 神经网络只能取得相对较小的成功，而现在神经网络非常成功的另一个重要原因是我们现在拥有的计算资源可以运行更大的模型。 联结主义的主要见解之一是，当动物的许多神经元一起工作时会变得聪明。单独神经元或小集合的神经元不是特别有用。

生物神经元不是特别稠密地连接在一起。如图 1.10 所示，几十年来，我们的机器学习模型中**每个神经元的连接数量**已经与哺乳动物的大脑在同一数量级上。

<img src=assets/1_10.png height=200 >

*图 1.10: 与日俱增的每神经元连接数。*(20 GoogLeNet)



如图 1.11 所示，就**神经元的总数目**而言，直到最近神经网络都是惊人的小。自从隐藏单元引入以来，人工神经网络的规模大约每 2.4 年扩大一倍。这种增长是由**更大内存**、**更快的计算机**和**更大的可用数据集**驱动的。更大的网络能够在更复杂的任务中实现更高的精度。这种趋势看起来将持续数十年。除非有能力迅速扩展的新技术，否则至少要到 21 世纪 50 年代，人工神经网络将才能具备与人脑相同数量级的神经元。

<img src=assets/1_11.png height=200 >

*图 1.11: 与日俱增的神经网络规模。(20 GoogLeNet)*

**现在看来，其神经元比一个水蛭还少的神经网络不能解决复杂的人工智能问题是不足为奇的。即使现在的网络，从计算系统角度来看它可能相当大的，但实际上它比相对原始的脊椎动物如青蛙的神经系统还要小。**

### 1.2.4 与日俱增的精度、复杂度和对现实世界的冲击

**神经图灵机** (Graves et al.,2014) 的引入，它能学习读取存储单元和向存储单元写入任意内容。这样的神经网络可以从期望行为的样本中学习简单的程序。例如，从杂乱和排好序的样本中学习对一系列数进行排序。这种自我编程技术正处于起步阶段，但原则上未来可以适用于几乎所有的任务。

深度学习的另一个最大的成就是其在 **强化学习**（ reinforcement learning）领域的扩展。在强化学习中，一个自主的智能体必须在没有人类操作者指导的情况下，通过试错来学习执行任务。 

总之， 深度学习是机器学习的一种方法。在过去几十年的发展中，它大量借鉴了我们关于人脑、统计学和应用数学的知识。近年来，得益于*更强大的计算机*、*更大的数据集*和*能够训练更深网络的技术*， 深度学习的普及性和实用性都有了极大的发展。未来几年充满了进一步提高深度学习并将它带到新领域的挑战和机遇。